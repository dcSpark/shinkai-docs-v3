---
title: 'Custom AI Models'
description: 'Text, title, and styling in standard markdown'
icon: 'robot'
---

<Tip>
Sections:
- Models comparison - table
- List of models + constantly updating -> Ollama
- Installing manual AI
- Custom AI installation

</Tip>


## AI Models


<ResponseField name="Parameters" type="AI Models">
  <Expandable title="Parameters definition">
    <ResponseField name="type" type={'"link" or "github"'} default="link">
    Link shows a button. GitHub shows the repo information at the url provided including the number of GitHub stars.
    </ResponseField>
    <ResponseField name="url" type="string">
    If `link`: What the button links to.
    
    If `github`: Link to the repository to load GitHub information from.
    </ResponseField>
    <ResponseField name="name" type="string">
    Text inside the button. Only required if `type` is a `link`.
    </ResponseField>

  </Expandable>
</ResponseField>

**Parameters** in AI models are like "settings" that adjust how the model processes information. They're the values that get fine-tuned during training to help the model make predictions, generate text, or recognize patterns. The more parameters a model has, the more detailed and powerful it can be, though it also requires more computing power.

**Quantization** is a technique used to reduce the size of AI models by simplifying the number of bits used to represent the parameters. This makes the model faster and more efficient without drastically losing accuracy.

| **Model**          | **Parameters**                     | **Best For**                                |
|--------------------|------------------------------------|---------------------------------------------|
| **Llama2**         | 7B, 13B                           | General text generation, lightweight tasks  |
| **Gemma2**         | 2B, 9B, 27B                       | Efficient text generation and language tasks|
| **Mistral**        | 7B                                | Lightweight multi-lingual tasks             |
| **Qwen2**          | 0.5B, 1.5B, 7B                    | Text processing, general AI tasks           |
| **Vicuna**         | 7B, 13B                           | Conversational AI, chat applications        |
| **MPT**            | 7B                                | Open-source, versatile AI for local use     |
| **CodeGemma**      | 2B, 7B                            | Code generation, instruction-following tasks|
| **LLaVA**          | 7B, 13B                           | Visual and language understanding tasks     |


