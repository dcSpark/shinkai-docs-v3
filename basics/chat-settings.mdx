---
title: 'Chat Settings'
description: 'How to optimize your chat responses'
icon: 'sliders'
---



You can access chat settings to adjust how the model generates text. By adjusting these settings, you can **fine-tune the balance between creativity and accuracy**, depending on the nature of your project or conversation.

## Understanding Chat Settings 
![Menu options](/images/chat-settings.jpg) 
<Tabs>
    <Tab title="Enable Stream">
        This toggle allows you to turn on or off streaming mode. When enabled, the model will stream responses word by word or in chunks rather than delivering the full response at once. This can create a more dynamic, conversational experience.

        <Note>If you want to use a tool in your prompt, you need to turn this option off to do so, due to a Ollama limitation.</Note>
      </Tab>
    <Tab title="Temperature">
        The temperature controls the **randomness** of the AI’s responses.
    
          - A lower temperature (< 1) makes the model more deterministic, meaning it will generate more focused and repetitive responses.
          - A higher temperature (> 1) increases randomness and creativity, making the responses less predictable but can lead to less coherent results.
        <Note>For balanced creativity and coherence, a temperature between `0.7` and `1.0` is commonly used.</Note>
    </Tab>
    <Tab title="Top P (Nucleus Sampling)">
        This setting affects how the model selects words based on cumulative probability.
        - `Top P` sets a threshold for considering the most likely word choices. For example, a `Top P` of `0.9` means the model will sample from the smallest possible set of words whose combined probability is 90%.
        - Lower `Top P` values result in more conservative responses, while higher values (closer to `1.0`) allow for more diversity.
        
        This approach balances diversity and relevance by focusing on a subset of probable outcomes.
        <Note>**Recommendation**: Values around `0.8` to `0.9` are often effective for maintaining meaningful yet varied outputs.</Note>
    </Tab>
    <Tab title="Top K">
        `Top K` controls how many of the highest probability word choices are considered at each step.
        - For instance, `Top K = 40` means the model will only consider the top 40 most likely words, filtering out less probable options.
        - A lower `Top K` (e.g., `5` or `10`) will make the responses more deterministic, while a higher Top K (e.g., `50` or `100`) allows for more variety in responses.
        <Note>**Recommendation**: A typical value is between `20` and `50`, depending on how much diversity you want in responses.</Note>
    </Tab>
    <Tab title="Custom Prompt">
        This field allows you to input a custom prompt that adjusts the context or behavior of the AI.
        
        You can add specific instructions here, such as “Respond concisely” or “Act as a friendly assistant,” which will influence how the AI interacts within the session.
    </Tab>
</Tabs>

### Setting Up your Chat for Improved Responses

To achieve optimal responses from an AI model, consider the following setup:
<Steps>
  <Step title="Determine Your Goals"> 
    - For **creative tasks** (*e.g., storytelling*), use a higher temperature (around `0.8`) with moderate top-p (`0.9`) and top-k (`30`).
    - For **factual or structured responses** (*e.g., technical writing*), lower temperature (`0.5`) with lower top-p (`0.7`) and top-k (`20`) may be preferable.
  </Step>
  <Step title="Experiment and Iterate">
    - Start with recommended values and adjust based on output quality.
    - Monitor for balance between creativity and coherence; **tweak one parameter at a time to understand its impact**.
  </Step>
  <Step title="Utilize Feedback Loops">
    - Incorporate user feedback or evaluation metrics to refine settings further.
  </Step>
</Steps>
By carefully tuning these parameters, you can significantly enhance the performance of AI models in generating relevant, coherent, and engaging text outputs tailored to specific applications or audiences.

     