---
title: 'Installation and Setup Guide'
description: 'Start experiencing the power of Shinkai in under 5 minutes'
icon: 'wrench'
---
<Info>
 Minimum System Requirements: 

 Windows/Linux -> CPU: 4 Cores | RAM: 16 GB

 MacOs -> Processor M1+ (Not Intel compatible)
</Info>
## Shinkai Desktop App
Getting started with Shinkai is quick and easy. Follow these steps to install and set up Shinkai on your device.

### 1. Download the app to your device. 
Visit the [Shinkai website](https://www.shinkai.com/) and click on the "**Download**" button. Shinkai supports Windows, Mac, and Linux platforms.

<Frame>
  [<img src="/images/download.png"  style={{ borderRadius: '0.5rem' }}/>](https://www.shinkai.com/)
</Frame>

### 2. Install the app
Once downloaded, run the installation file and follow the on-screen instructions to install Shinkai.

### 3. Launch Shinkai
After installation, open the Shinkai app. The first time you launch it, you'll be guided through a quick setup process.

<Frame>
  <img src="/images/welcome.jpg"  style={{ borderRadius: '0.5rem' }}/>
</Frame>


#### Setting up Shinkai
To start using your local AI with Shinkai you will need to install local AI agents or models. 

After initializing your app you will be prompted to **install recommended models** according to your decice specs. You can see the full list of models available by clicking '**Show all models**.'

<Frame>
  <img src="/images/models-setup.jpg"  style={{ borderRadius: '0.5rem' }}/>
</Frame>



<AccordionGroup>

<Accordion icon="robot" title="AI model guideline according to your RAM">
  As a general rule, here is a brief guideline for model installation **according to your machine specs**: 

    **8GB RAM** ‚û° choose 7B models or smaller.
    _e.g., Gemma2 2b, Codegemma, Falcon, etc._

    **16GB RAM** ‚û° choose 7B, 13B models or smaller.
    _e.g., Llama 3.1 8b, Mistral Nemo 12b, Nexusraven, etc._

    **32GB RAM** ‚û° choose 7B, 13B, 15B, 30B models or smaller.
    _e.g., Codestral, etc._

    **64GB RAM** ‚û° choose 7B, 13B, 15B, 30B models or smaller. You might be able to go higher than that.
    _e.g., Alfred, etc._

    **96GB RAM+** ‚û° any model size should work for you. ü¶æ
</Accordion>
<Accordion icon="laptop" title="Which AI model should I install?">
  As a general rule: 
  
  üëü For **lightweight, fast AI needs** (short conversations, basic text generation): Go with _Gemma2 2b_ or _LLaVA Phi 3_.
  
  ‚öñÔ∏è  For **balance between complexity and speed**: _Llama 3.1 8b_ is the best choice.
  
  üß†  For **handling large documents and complex reasoning**: Opt for _Mistral Nemo 12b_, but keep in mind it will require more resources and be slower.

  _Ultimately, your choice depends on the type of content, performance requirements, and hardware limitations you have in your setup._
</Accordion>
<Accordion icon="book-open" title="Understanding the 'b' in model names">
  The "**b**" in model names refers to the **number of parameters in the model, measured in billions**. Parameters are the variables the model uses to make predictions, learn language patterns, and generate outputs.

    üëÄ **The more parameters a model has, the more complex patterns it can learn**, but this also means:
    - Increased resource consumption (memory, disk space, computational power)
    - Longer inference time (slower responses, unless optimized)

    üëá Here‚Äôs a general guideline for understanding parameter sizes:

    **2b - 8b models** are smaller, faster, and can handle simpler tasks. They‚Äôre more lightweight and good for smaller, real-time tasks.

    **10b - 70b models** are larger, slower, and better for complex, nuanced tasks. They have better performance on language understanding and generation, but are resource-intensive.

    üíª _You have to keep in mind your own machine's specs when selecting a model._
</Accordion>

</AccordionGroup>

## Installing Shinkai Visor (Chrome Extension)

Installing the [Shinkai Chrome extension](https://chromewebstore.google.com/u/1/detail/shinkai-visor-supercharge/emahbbinjjmancgckmoodjficjdkjkif) enhances Shinkai‚Äôs capabilities by allowing it to seamlessly interact with your web browsing experience. 

The extension enables Shinkai to access, summarize, and organize web content directly in your browser, making tasks like research, reading, and data collection faster and more efficient. 

### Install the Chrome Extension

- Go to the [Chrome Web Store](https://chromewebstore.google.com/u/1/detail/shinkai-visor-supercharge/emahbbinjjmancgckmoodjficjdkjkif).
- Click the **Add to Chrome** button.
- Pin Shinkai to your extension navbar.


![Visor - Chrome Extension](/images/visor.png)

Shinkai Visor acts as a smart assistant while you browse, providing real-time insights and automating tasks, all while keeping your data private and secure on your device.

### Connecting Shinkai Visor to your Desktop App
Connecting Shinkai Visor to the Shinkai Desktop App provides a more powerful and integrated AI experience. 

With this connection, your desktop app can pull data and insights directly from your web browsing activities, enabling seamless cross-platform AI assistance.

#### 1. Export your connection
In your Desktop app, go to Settings > Export Connection > Enter a passphrase (_make sure to remember this_) > Click **Generate connection file**.

Save the file in your device.

<Frame>
  <img src="/images/export-connection.jpg"  style={{ borderRadius: '0.5rem' }}/>
</Frame>

#### 2. Restore Connection in Visor (Chrome extension)

- Open Visor in Chrome > Click **Restore**.

<Frame>
  <img src="/images/restore.jpg"  style={{ borderRadius: '0.5rem' }}/>
</Frame>

- Upload the connection file you just saved.
- Enter your passphrase.
- Click '**Restore Connection**'
<Frame>
  <img src="/images/restore-2.jpg"  style={{ borderRadius: '0.5rem' }}/>
</Frame>
You are all set. You can navigate your local folders, save webpages, initiate chats with your AI while navigating and storing your information locally. 